import torch
import torch.nn as nn
import torch.nn.functional as F
from .Xception import Xception
from torchvision import models

class SiameseNetwork(nn.Module):
    def __init__(self, backbone="resnet50"):
        '''
        Creates a siamese network with a network from torchvision.models as backbone.

            Parameters:
                    backbone (str): Options of the backbone networks can be found at https://pytorch.org/vision/stable/models.html
        '''

        super().__init__()

        if backbone not in models.__dict__:
            self.backbone = Xception()

            # Get the number of features that are outputted by the last layer of backbone network.
            out_features = list(self.backbone.modules())[-1].out_features

            # Create an MLP (multi-layer perceptron) as the classification head.
            # Classifies if provided combined feature vector of the 2 images represent same player or different.
            self.cls_head = nn.Sequential(
                nn.Dropout(p=0.5),
                nn.Linear(out_features, 512),
                nn.BatchNorm1d(512),
                nn.ReLU(),

                nn.Dropout(p=0.5),
                nn.Linear(512, 64),
                nn.BatchNorm1d(64),
                nn.Sigmoid(),
                nn.Dropout(p=0.5),

                nn.Linear(64, 1),
                nn.Sigmoid(),
            )

        else :
                # Create a backbone network from the pretrained models provided in torchvision.models

                self.backbone = models.__dict__[backbone](pretrained=True, progress=True)

                 # Get the number of features that are outputted by the last layer of backbone network.
                out_features = list(self.backbone.modules())[-1].out_features


                # Create an MLP (multi-layer perceptron) as the classification head.
                # Classifies if provided combined feature vector of the 2 images represent same player or different.
                self.cls_head = nn.Sequential(
                    nn.Dropout(p=0.5),
                    nn.Linear(out_features, 512),
                    nn.BatchNorm1d(512),
                    nn.ReLU(),

                    nn.Dropout(p=0.5),
                    nn.Linear(512, 64),
                    nn.BatchNorm1d(64),
                    nn.Sigmoid(),
                    nn.Dropout(p=0.5),

                    nn.Linear(64, 1),
                    nn.Sigmoid(),
                )

    def forward(self, img1, img2):
        '''
        Returns the similarity value between two images.

            Parameters:
                    img1 (torch.Tensor): shape=[b, 3, 224, 224]
                    img2 (torch.Tensor): shape=[b, 3, 224, 224]

            where b = batch size

            Returns:
                    output (torch.Tensor): shape=[b, 1], Similarity of each pair of images
        '''

        # Pass the both images through the backbone network to get their seperate feature vectors
        feat1 = self.backbone(img1)
        feat2 = self.backbone(img2)

        # Multiply (element-wise) the feature vectors of the two images together,
        # to generate a combined feature vector representing the similarity between the two.
        combined_features = feat2 * feat1



        # Pass the combined feature vector through classification head to get similarity value in the range of 0 to 1.
        output = self.cls_head(combined_features)
        return output


